
feed dict is off
    should be:
    {
        states: si #states
        ac: a #actions
        adv: adv #discount(rewards + gamma * vpred_t[1:] - vpred_t[:-1],
                 #gamma*lambda_)
        r: r #discount(rewards + [r], gamma)[:-1]
        features...
    }

    loss calc uses ac, adv, r

implement discount(x, gamma) function
    scipy.signal.lfilter([1], [1, -gamma], x[::-1], axis=0)[::-1]

ensure the model actually works

better GLOBAL summary scalars (reward, loss, etc)

save weights, load weights on startup

add timing information (length of training, testing, initializing, etc)

ensure model is correct
    value_in vs reward_in?
    summed rewards inputs??
    advantage discount filter

find and fix illegal instruction error

